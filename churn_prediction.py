# -*- coding: utf-8 -*-
"""CHURN PREDICTION.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1I3GTyR2xGTZJCZLWBINwiw4bHvjYK4pY
"""

import pandas as pd

data = pd.read_csv('data_file.csv')

data.head()

data.drop("customerID",axis='columns',inplace=True)

data.dtypes

data.TotalCharges.values

pd.to_numeric(data.TotalCharges,errors="coerce").isnull()

df1=data[data.TotalCharges!=" "]
df1.shape

data.shape

tenure_yes=data[data.Churn!="Yes"].tenure
tenure_yes

tenure_no=data[data.Churn!="No"].tenure
tenure_no

import matplotlib.pyplot as plt

plt.hist([tenure_yes,tenure_no],label=["churn_yes","churn_no"])
plt.xlabel("Tenure")
plt.ylabel("No. of cutomers")
plt.legend()

MonthlyCharges_yes=data[data.Churn!="Yes"].MonthlyCharges
MonthlyCharges_no=data[data.Churn!="No"].MonthlyCharges
plt.hist([MonthlyCharges_yes,MonthlyCharges_no],label=["MonthlyCharges_yes","MonthlyCharges_no"])
plt.xlabel("MonthlyCharges")
plt.ylabel("No. of cutomers")
plt.legend()

def object_unique(df1):
  for column in df1:
    if df1[column].dtypes=="object":
      print(f'{column}: {df1[column].dtype} {df1[column].unique()}')

object_unique(df1)

df1.replace("No internet service","No",inplace=True)
df1.replace("No phone service","No",inplace=True)

object_unique(df1)

df1.replace({"No":0,"Yes":1},inplace=True)

df1

df1.replace({"Female":1,"Male":0},inplace=True)

object_unique(df1)

df2=pd.get_dummies(data=df1,columns=["InternetService","Contract","PaymentMethod"])
df2

df2.sample(4)

df2.columns

cols_to_scale=["tenure","MonthlyCharges","TotalCharges"]

# prompt: scale cols_to_scale colums of df2 dataframe using sklearn preprocessing

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])
df2.head()

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
df2[cols_to_scale] = scaler.fit_transform(df2[cols_to_scale])
df2.head()

# prompt: scale cols_to_scale colums of df2 dataframe using sklearn preprocessing using min max scalr

from sklearn.preprocessing import MinMaxScaler
df2[cols_to_scale] = MinMaxScaler().fit_transform(df2[cols_to_scale])
df2.head()

X=df2.drop(["Churn"],axis=1)
Y=df2["Churn"]

# prompt: divide X and Y into testing training 80 and 20 % random state=5 also import sklearn

from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=5)

# prompt: use tensoer flow keras library to generate model, fit model

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Dropout
from tensorflow.keras.optimizers import Adam

model = Sequential([
    Dense(20, activation='relu', input_shape=(X_train.shape[1],)),
    Dense(1, activation='sigmoid')
])

model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])

model.fit(X_train, y_train, epochs=100, batch_size=128)

model.evaluate(X_test, y_test)

# prompt: predict the model

pred=model.predict(X_test)
pred

# prompt: if element in pred is greater than 0.5 apend 1 in y_pred list and if  less than 0.5 apend 0 in y_pred list

y_pred = []
for i in pred:
    if i >= 0.5:
        y_pred.append(1)
    else:
        y_pred.append(0)

y_test[:10]

y_pred[:10]

# prompt: classification report

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred))

# prompt: make confusion matrix heat map

import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(10,10))
sns.heatmap(cm, annot=True, fmt=".3f",linewidths=.5, square=True, cmap='Blues_r')
plt.xlabel('Predicted Values')
plt.ylabel('Actual Values')
plt.title('Confusion Matrix')
plt.show()